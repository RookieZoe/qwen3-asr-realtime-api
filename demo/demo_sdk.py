#!/usr/bin/env python3
"""
Qwen3-ASR Realtime Python Demo
ä½¿ç”¨å®˜æ–¹ DashScope SDK è¿æ¥ç§æœ‰åç«¯æœåŠ¡

åŠŸèƒ½:
- VAD æ¨¡å¼: å®æ—¶å½•éŸ³è¯†åˆ« (éœ€è¦ pyaudio)
- Manual æ¨¡å¼: éŸ³é¢‘æ–‡ä»¶è¯†åˆ« (æ”¯æŒæœ¬åœ°æ–‡ä»¶å’Œ HTTP URL)
- æ”¯æŒå®æ—¶æ˜¾ç¤ºè¯†åˆ«ç»“æœ
- è‡ªåŠ¨è½¬æ¢ MP3/WAV/M4A/OGG ç­‰æ ¼å¼ä¸º PCM (éœ€è¦ pydub + ffmpeg)

ä¾èµ–:
  pip install dashscope>=1.25.6
  pip install pydub  # éŸ³é¢‘æ ¼å¼è½¬æ¢ (å¯é€‰, ä»… Manual æ¨¡å¼éœ€è¦)
  pip install pyaudio  # å®æ—¶å½•éŸ³ (å¯é€‰, ä»… VAD æ¨¡å¼éœ€è¦)

  # ffmpeg éœ€è¦ç³»ç»Ÿå®‰è£…:
  # Ubuntu/Debian: apt install ffmpeg
  # macOS: brew install ffmpeg
"""

import argparse
import base64
import os
import signal
import sys
import tempfile
import time
from datetime import datetime
from urllib.parse import urlparse

# å®‰è£…: pip install dashscope>=1.25.6
import dashscope
from dashscope.audio.qwen_omni import MultiModality, OmniRealtimeCallback, OmniRealtimeConversation
from dashscope.audio.qwen_omni.omni_realtime import TranscriptionParams
from dotenv import load_dotenv

load_dotenv()

# ==================== é…ç½® ====================

# ç§æœ‰åç«¯æœåŠ¡åœ°å€ (ä¿®æ”¹ä¸ºä½ çš„æœåŠ¡åœ°å€)
DEFAULT_WS_URL = "ws://localhost:8080/api-ws/v1/realtime"
# DEFAULT_WS_URL = "wss://dashscope.aliyuncs.com/api-ws/v1/realtime"

# API Key (ç§æœ‰æœåŠ¡é€šå¸¸ä¸éœ€è¦ï¼Œä½† SDK è¦æ±‚æä¾›ï¼Œå¯ä»¥éšä¾¿å¡«)
DEFAULT_API_KEY = os.getenv("QWEN3_DASHSCOPE_API_KEY", "")


# ==================== æ—¥å¿—é…ç½® ====================


def setup_logging():
    """é…ç½®æ—¥å¿—è¾“å‡º"""
    import logging

    logger = logging.getLogger("dashscope")
    logger.setLevel(logging.INFO)

    # æ¸…é™¤å·²æœ‰å¤„ç†å™¨
    logger.handlers = []

    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(logging.INFO)
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.propagate = False
    return logger


# ==================== å›è°ƒå¤„ç† ====================


class ASRCallback(OmniRealtimeCallback):
    """å®æ—¶è¯†åˆ«å›è°ƒå¤„ç†"""

    def __init__(self):
        self.confirmed_text = ""
        self.stash_text = ""
        self.is_running = True

    def on_open(self):
        print("\nâœ… è¿æ¥æˆåŠŸ")

    def on_close(self, code, msg):
        print(f"\nâŒ è¿æ¥å…³é—­, code: {code}, msg: {msg}")
        self.is_running = False

    def on_event(self, response):
        event_type = response.get("type", "")

        # ä¼šè¯åˆ›å»º
        if event_type == "session.created":
            session_id = response.get("session", {}).get("id", "unknown")
            print(f"ğŸ“¢ ä¼šè¯åˆ›å»º: {session_id}")

        # ä¼šè¯æ›´æ–°
        elif event_type == "session.updated":
            print("ğŸ“¢ ä¼šè¯é…ç½®æ›´æ–°æˆåŠŸ")

        # è¯­éŸ³å¼€å§‹ (VAD æ¨¡å¼)
        elif event_type == "input_audio_buffer.speech_started":
            print("\nğŸ¤ [æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹]")

        # è¯­éŸ³ç»“æŸ (VAD æ¨¡å¼)
        elif event_type == "input_audio_buffer.speech_stopped":
            print("ğŸ›‘ [æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ]")

        # å®æ—¶è¯†åˆ«ç»“æœ
        elif event_type == "conversation.item.input_audio_transcription.text":
            text = response.get("text", "")
            stash = response.get("stash", "")
            language = response.get("language", "")
            emotion = response.get("emotion", "")

            # æ›´æ–°å·²ç¡®è®¤æ–‡æœ¬
            if text:
                self.confirmed_text = text
            self.stash_text = stash

            # å®æ—¶æ˜¾ç¤º
            display_text = text + stash
            print(f"\rğŸ“ è¯†åˆ«ä¸­: {display_text[:80]}...", end="", flush=True)

        # æœ€ç»ˆè¯†åˆ«ç»“æœ
        elif event_type == "conversation.item.input_audio_transcription.completed":
            transcript = response.get("transcript", "")
            language = response.get("language", "")
            emotion = response.get("emotion", "")

            self.confirmed_text += transcript
            self.stash_text = ""

            print(f"\nâœ… [è¯†åˆ«å®Œæˆ]")
            print(f"   æ–‡æœ¬: {transcript}")
            print(f"   è¯­è¨€: {language}")
            print(f"   æƒ…æ„Ÿ: {emotion}")

        # ä¼šè¯ç»“æŸ
        elif event_type == "session.finished":
            print("\nğŸ ä¼šè¯ç»“æŸ")
            self.is_running = False

        # é”™è¯¯
        elif event_type == "error":
            error = response.get("error", {})
            print(f"\nâŒ [é”™è¯¯] {error.get('message', 'Unknown error')}")


# ==================== éŸ³é¢‘å¤„ç† ====================


def is_remote_url(path: str) -> bool:
    """æ£€æŸ¥è·¯å¾„æ˜¯å¦ä¸ºè¿œç¨‹ URL"""
    try:
        parsed = urlparse(path)
        return parsed.scheme in ("http", "https")
    except Exception:
        return False


def download_remote_audio(url: str, timeout: int = 60) -> str:
    """
    ä¸‹è½½è¿œç¨‹éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•

    Args:
        url: è¿œç¨‹éŸ³é¢‘æ–‡ä»¶ URL
        timeout: ä¸‹è½½è¶…æ—¶æ—¶é—´ (ç§’)

    Returns:
        ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    """
    import urllib.error
    import urllib.request

    print(f"ğŸŒ ä¸‹è½½è¿œç¨‹éŸ³é¢‘: {url}")

    # ä» URL æå–æ–‡ä»¶æ‰©å±•å
    parsed = urlparse(url)
    path = parsed.path
    ext = os.path.splitext(path)[1] or ".wav"

    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    fd, temp_path = tempfile.mkstemp(suffix=ext, prefix="qwen_asr_")
    os.close(fd)

    try:
        # è®¾ç½®è¯·æ±‚å¤´ (æ¨¡æ‹Ÿæµè§ˆå™¨)
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
        request = urllib.request.Request(url, headers=headers)

        # ä¸‹è½½æ–‡ä»¶
        with urllib.request.urlopen(request, timeout=timeout) as response:
            total_size = response.headers.get("Content-Length")
            if total_size:
                total_size = int(total_size)
                print(f"   æ–‡ä»¶å¤§å°: {total_size / 1024 / 1024:.2f} MB")

            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_path, "wb") as f:
                downloaded = 0
                chunk_size = 8192
                while True:
                    chunk = response.read(chunk_size)
                    if not chunk:
                        break
                    f.write(chunk)
                    downloaded += len(chunk)
                    if total_size:
                        progress = downloaded / total_size * 100
                        print(f"\r   ä¸‹è½½è¿›åº¦: {progress:.1f}%", end="", flush=True)

        print(f"\nâœ… ä¸‹è½½å®Œæˆ: {temp_path}")
        return temp_path

    except urllib.error.HTTPError as e:
        os.unlink(temp_path)
        raise RuntimeError(f"HTTP é”™è¯¯ {e.code}: {e.reason}")
    except urllib.error.URLError as e:
        os.unlink(temp_path)
        raise RuntimeError(f"URL é”™è¯¯: {e.reason}")
    except Exception as e:
        os.unlink(temp_path)
        raise RuntimeError(f"ä¸‹è½½å¤±è´¥: {e}")


def convert_audio_to_pcm(input_path: str) -> str:
    """
    å°†ä»»æ„éŸ³é¢‘æ ¼å¼è½¬æ¢ä¸º PCM (16kHz, 16-bit, mono)

    æ”¯æŒæ ¼å¼: MP3, WAV, M4A, OGG, FLAC, AAC ç­‰

    Args:
        input_path: è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        è½¬æ¢åçš„ PCM æ–‡ä»¶è·¯å¾„ (ä¸´æ—¶æ–‡ä»¶)

    Requires:
        pip install pydub
        ffmpeg éœ€è¦å®‰è£…åœ¨ç³»ç»Ÿä¸­
    """
    try:
        from pydub import AudioSegment
    except ImportError:
        raise RuntimeError(
            "éœ€è¦å®‰è£… pydub æ¥è½¬æ¢éŸ³é¢‘æ ¼å¼: pip install pydub\n"
            "åŒæ—¶éœ€è¦å®‰è£… ffmpeg: apt install ffmpeg æˆ– brew install ffmpeg"
        )

    print(f"ğŸ”„ è½¬æ¢éŸ³é¢‘æ ¼å¼ä¸º PCM (16kHz, 16-bit, mono)...")

    try:
        # åŠ è½½éŸ³é¢‘æ–‡ä»¶ (pydub ä¼šè‡ªåŠ¨æ£€æµ‹æ ¼å¼)
        audio = AudioSegment.from_file(input_path)

        # è½¬æ¢å‚æ•°
        audio = audio.set_frame_rate(16000)  # 16kHz
        audio = audio.set_sample_width(2)  # 16-bit
        audio = audio.set_channels(1)  # mono

        # å¯¼å‡ºä¸º raw PCM
        fd, pcm_path = tempfile.mkstemp(suffix=".pcm", prefix="qwen_asr_")
        os.close(fd)

        # å¯¼å‡ºä¸º raw PCM æ ¼å¼
        audio.export(pcm_path, format="s16le", parameters=["-ar", "16000", "-ac", "1"])

        duration = len(audio) / 1000  # æ¯«ç§’è½¬ç§’
        print(f"âœ… è½¬æ¢å®Œæˆ: {duration:.1f}s, {os.path.getsize(pcm_path)} bytes")

        return pcm_path

    except Exception as e:
        raise RuntimeError(f"éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}")


def list_audio_devices():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡"""
    try:
        import pyaudio
    except ImportError:
        print("è¯·å…ˆå®‰è£… pyaudio: pip install pyaudio")
        return []

    audio = pyaudio.PyAudio()
    devices = []

    print("\nğŸ¤ å¯ç”¨éŸ³é¢‘è¾“å…¥è®¾å¤‡:")
    print("-" * 60)

    for i in range(audio.get_device_count()):
        info = audio.get_device_info_by_index(i)
        if int(info["maxInputChannels"]) > 0:  # ä»…æ˜¾ç¤ºè¾“å…¥è®¾å¤‡
            is_default = info.get("index") == audio.get_default_input_device_info().get("index")
            default_marker = " â­ (é»˜è®¤)" if is_default else ""
            print(f"  [{i}] {info['name']}{default_marker}")
            print(
                f"      é‡‡æ ·ç‡: {int(info['defaultSampleRate'])} Hz, è¾“å…¥é€šé“: {int(info['maxInputChannels'])}"
            )
            devices.append({"index": i, "name": info["name"], "is_default": is_default})

    print("-" * 60)
    audio.terminate()
    return devices


def read_audio_chunks(file_path, chunk_size=3200):
    """æŒ‰å—è¯»å–éŸ³é¢‘æ–‡ä»¶ (3200 bytes = 0.1s PCM16/16kHz)"""
    with open(file_path, "rb") as f:
        while chunk := f.read(chunk_size):
            yield chunk


def send_audio_file(conversation, file_path, delay=0.1):
    """å‘é€éŸ³é¢‘æ–‡ä»¶"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    print(f"ğŸ“ æ­£åœ¨å¤„ç†: {file_path}")
    print(f"â±ï¸  å‘é€é—´éš”: {delay}s (æ¨¡æ‹Ÿå®æ—¶é‡‡é›†)")
    print("ğŸ›‘ æŒ‰ Ctrl+C åœæ­¢\n")

    total_bytes = 0
    start_time = time.time()

    for chunk in read_audio_chunks(file_path):
        audio_b64 = base64.b64encode(chunk).decode("ascii")
        conversation.append_audio(audio_b64)
        total_bytes += len(chunk)
        time.sleep(delay)

    elapsed = time.time() - start_time
    print(f"\nğŸ“Š å‘é€å®Œæˆ: {total_bytes} bytes in {elapsed:.1f}s")


# ==================== ä¸»ç¨‹åº ====================


def run_vad_mode(url, api_key, language="auto", device_index=None):
    """
    VAD æ¨¡å¼: å®æ—¶å½•éŸ³è¯†åˆ«

    éœ€è¦å®‰è£…: pip install pyaudio

    Args:
        url: WebSocket æœåŠ¡åœ°å€
        api_key: API Key
        language: è¯†åˆ«è¯­è¨€
        device_index: éŸ³é¢‘è¾“å…¥è®¾å¤‡ç´¢å¼• (None è¡¨ç¤ºä½¿ç”¨é»˜è®¤è®¾å¤‡)
    """
    try:
        import pyaudio
    except ImportError:
        print("è¯·å…ˆå®‰è£… pyaudio: pip install pyaudio")
        return

    print("=" * 60)
    print("ğŸ™ï¸ VAD æ¨¡å¼ - å®æ—¶å½•éŸ³è¯†åˆ«")
    print("=" * 60)
    print(f"æœåŠ¡ç«¯: {url}")
    print(f"è¯­è¨€: {language}")

    # è·å–è®¾å¤‡ä¿¡æ¯
    audio = pyaudio.PyAudio()
    if device_index is not None:
        try:
            device_info = audio.get_device_info_by_index(device_index)
            print(f"éŸ³é¢‘è®¾å¤‡: [{device_index}] {device_info['name']}")
        except Exception as e:
            print(f"âŒ æ— æ•ˆçš„è®¾å¤‡ç´¢å¼• {device_index}: {e}")
            audio.terminate()
            return
    else:
        device_info = audio.get_default_input_device_info()
        print(f"éŸ³é¢‘è®¾å¤‡: [é»˜è®¤] {device_info['name']}")

    print("æŒ‰ Ctrl+C åœæ­¢å½•éŸ³\n")

    # åˆ›å»ºå›è°ƒ
    callback = ASRCallback()

    # åˆ›å»ºä¼šè¯
    conversation = OmniRealtimeConversation(
        model="qwen3-asr-flash-realtime", url=url, callback=callback
    )

    # é…ç½® (language=auto æ—¶ä¸è®¾ç½® language å‚æ•°ï¼Œè®©æœåŠ¡ç«¯è‡ªåŠ¨æ£€æµ‹)
    if language == "auto":
        transcription_params = TranscriptionParams(sample_rate=16000, input_audio_format="pcm")
    else:
        transcription_params = TranscriptionParams(
            language=language, sample_rate=16000, input_audio_format="pcm"
        )

    # è¿æ¥
    conversation.connect()

    conversation.update_session(
        output_modalities=[MultiModality.TEXT],
        enable_turn_detection=True,
        turn_detection_type="server_vad",
        turn_detection_threshold=0.3,
        turn_detection_silence_duration_ms=500,
        enable_input_audio_transcription=True,
        transcription_params=transcription_params,
    )

    # å½•éŸ³å‚æ•°
    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000

    # åˆå§‹åŒ–å½•éŸ³ (å¤ç”¨å·²åˆ›å»ºçš„ audio å®ä¾‹)
    stream = audio.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        input=True,
        frames_per_buffer=CHUNK,
        input_device_index=device_index,
    )

    print("ğŸ¤ å¼€å§‹å½•éŸ³...\n")

    try:
        while callback.is_running:
            # è¯»å–éŸ³é¢‘æ•°æ®
            data = stream.read(CHUNK, exception_on_overflow=False)

            # è½¬æ¢ä¸º base64 å‘é€
            audio_b64 = base64.b64encode(data).decode("ascii")
            conversation.append_audio(audio_b64)

    except KeyboardInterrupt:
        print("\n\nğŸ›‘ åœæ­¢å½•éŸ³")
    finally:
        stream.stop_stream()
        stream.close()
        audio.terminate()

        # ç»“æŸä¼šè¯
        conversation.end_session()
        time.sleep(2)
        conversation.close()

        print(f"\n{'=' * 60}")
        print(f"ğŸ“ æœ€ç»ˆè¯†åˆ«ç»“æœ:\n{callback.confirmed_text}")
        print(f"{'=' * 60}")


def run_manual_mode(url, api_key, audio_file, language="auto", delay=0.1):
    """
    Manual æ¨¡å¼: éŸ³é¢‘æ–‡ä»¶è¯†åˆ«

    æ”¯æŒæœ¬åœ°æ–‡ä»¶è·¯å¾„å’Œ HTTP/HTTPS è¿œç¨‹ URL
    """
    print("=" * 60)
    print("ğŸ“ Manual æ¨¡å¼ - éŸ³é¢‘æ–‡ä»¶è¯†åˆ«")
    print("=" * 60)
    print(f"æœåŠ¡ç«¯: {url}")
    print(f"æ–‡ä»¶: {audio_file}")
    print(f"è¯­è¨€: {language}")
    print(f"å‘é€é—´éš”: {delay}s\n")

    # å¤„ç†è¿œç¨‹ URL
    temp_file = None
    pcm_file = None
    local_audio_file = audio_file

    if is_remote_url(audio_file):
        try:
            temp_file = download_remote_audio(audio_file)
            local_audio_file = temp_file
        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿œç¨‹æ–‡ä»¶å¤±è´¥: {e}")
            return

    # æ£€æµ‹æ˜¯å¦éœ€è¦è½¬æ¢æ ¼å¼ (é .pcm æ–‡ä»¶éƒ½éœ€è¦è½¬æ¢)
    file_ext = os.path.splitext(local_audio_file)[1].lower()
    if file_ext != ".pcm":
        try:
            pcm_file = convert_audio_to_pcm(local_audio_file)
            local_audio_file = pcm_file
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            # æ¸…ç†å·²ä¸‹è½½çš„ä¸´æ—¶æ–‡ä»¶
            if temp_file and os.path.exists(temp_file):
                os.unlink(temp_file)
            return

    # åˆå§‹åŒ–å˜é‡
    callback = None
    conversation = None

    try:
        # åˆ›å»ºå›è°ƒ
        callback = ASRCallback()

        # åˆ›å»ºä¼šè¯
        conversation = OmniRealtimeConversation(
            model="qwen3-asr-flash-realtime", url=url, callback=callback
        )

        # é…ç½® (language=auto æ—¶ä¸è®¾ç½® language å‚æ•°ï¼Œè®©æœåŠ¡ç«¯è‡ªåŠ¨æ£€æµ‹)
        if language == "auto":
            transcription_params = TranscriptionParams(sample_rate=16000, input_audio_format="pcm")
        else:
            transcription_params = TranscriptionParams(
                language=language, sample_rate=16000, input_audio_format="pcm"
            )

        # è¿æ¥
        conversation.connect()

        conversation.update_session(
            output_modalities=[MultiModality.TEXT],
            enable_turn_detection=False,  # Manual æ¨¡å¼å…³é—­ VAD
            enable_input_audio_transcription=True,
            transcription_params=transcription_params,
        )

        # ç­‰å¾…ä¼šè¯é…ç½®å®Œæˆ
        time.sleep(1)

        # å‘é€éŸ³é¢‘ (ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„)
        send_audio_file(conversation, local_audio_file, delay)

        # æäº¤è¯†åˆ« (Manual æ¨¡å¼éœ€è¦)
        print("\nğŸ“¤ æäº¤è¯†åˆ«...")
        conversation.commit()

        # ç­‰å¾…è¯†åˆ«å®Œæˆ
        time.sleep(3)

        # ç»“æŸä¼šè¯
        print("ğŸ ç»“æŸä¼šè¯...")
        conversation.end_session()

        # ç­‰å¾…ç»“æœ
        timeout = 30
        start = time.time()
        while callback.is_running and time.time() - start < timeout:
            time.sleep(0.5)

    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
    finally:
        if conversation is not None:
            conversation.close()

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for tmp in [pcm_file, temp_file]:
            if tmp and os.path.exists(tmp):
                try:
                    os.unlink(tmp)
                except Exception:
                    pass
        if pcm_file or temp_file:
            print("ğŸ—‘ï¸ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

        print(f"\n{'=' * 60}")
        if callback is not None:
            print(f"ğŸ“ æœ€ç»ˆè¯†åˆ«ç»“æœ:\n{callback.confirmed_text}")
        else:
            print("ğŸ“ æœ€ç»ˆè¯†åˆ«ç»“æœ: (æ— )")
        print(f"{'=' * 60}")


# ==================== å‘½ä»¤è¡Œå…¥å£ ====================


def main():
    parser = argparse.ArgumentParser(
        description="Qwen3-ASR Realtime Python Demo",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åˆ—å‡ºå¯ç”¨éŸ³é¢‘è®¾å¤‡
  python demo_sdk.py --list-devices

  # VAD æ¨¡å¼ (ä½¿ç”¨é»˜è®¤éŸ³é¢‘è®¾å¤‡)
  python demo_sdk.py --mode vad --url ws://localhost:8080/api-ws/v1/realtime

  # VAD æ¨¡å¼ (æŒ‡å®šéŸ³é¢‘è®¾å¤‡)
  python demo_sdk.py --mode vad --device 2

  # Manual æ¨¡å¼ (æœ¬åœ°éŸ³é¢‘æ–‡ä»¶)
  python demo_sdk.py --mode manual --file test.wav

  # Manual æ¨¡å¼ (è¿œç¨‹ HTTP URL)
  python demo_sdk.py --mode manual --file https://example.com/audio.wav

  # æŒ‡å®šè¯­è¨€
  python demo_sdk.py --mode manual --file test.wav --language zh
        """,
    )

    parser.add_argument(
        "--mode",
        "-m",
        choices=["vad", "manual"],
        default="manual",
        help="è¯†åˆ«æ¨¡å¼: vad=å®æ—¶å½•éŸ³, manual=éŸ³é¢‘æ–‡ä»¶ (é»˜è®¤: manual)",
    )

    parser.add_argument(
        "--url", "-u", default=DEFAULT_WS_URL, help=f"WebSocket æœåŠ¡åœ°å€ (é»˜è®¤: {DEFAULT_WS_URL})"
    )

    parser.add_argument(
        "--file",
        "-f",
        help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ– HTTP URL (æ”¯æŒ MP3/WAV/M4A/OGG ç­‰æ ¼å¼, è‡ªåŠ¨è½¬æ¢ä¸º PCM)",
    )

    parser.add_argument(
        "--language",
        "-l",
        default="auto",
        choices=["auto", "zh", "en", "ja", "ko"],
        help="è¯†åˆ«è¯­è¨€ (é»˜è®¤: auto)",
    )

    parser.add_argument(
        "--delay", "-d", type=float, default=0.1, help="éŸ³é¢‘å‘é€é—´éš”, ç§’ (é»˜è®¤: 0.1)"
    )

    parser.add_argument(
        "--api-key", "-k", default=DEFAULT_API_KEY, help="API Key (æœ¬åœ°æœåŠ¡å¯éšæ„å¡«å†™)"
    )

    parser.add_argument(
        "--list-devices",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡",
    )

    parser.add_argument(
        "--device",
        type=int,
        default=None,
        help="éŸ³é¢‘è¾“å…¥è®¾å¤‡ç´¢å¼• (ä½¿ç”¨ --list-devices æŸ¥çœ‹å¯ç”¨è®¾å¤‡)",
    )

    args = parser.parse_args()

    # åˆ—å‡ºè®¾å¤‡æ¨¡å¼
    if args.list_devices:
        list_audio_devices()
        return

    # è®¾ç½®æ—¥å¿—
    setup_logging()

    # è®¾ç½® API Key
    dashscope.api_key = args.api_key

    # è¿è¡Œ
    if args.mode == "vad":
        run_vad_mode(args.url, args.api_key, args.language, args.device)
    else:
        if not args.file:
            print("âŒ Manual æ¨¡å¼éœ€è¦æŒ‡å®š --file å‚æ•°")
            parser.print_help()
            sys.exit(1)
        run_manual_mode(args.url, args.api_key, args.file, args.language, args.delay)


if __name__ == "__main__":
    main()
