# Qwen3-ASR Realtime Server Docker Compose Example
#
# Usage:
#   1. Copy this file: cp docker-compose.yml compose.yml
#   2. Modify settings as needed
#   3. Start: docker compose up -d
#   4. View logs: docker compose logs -f
#   5. Stop: docker compose down

services:
  qwen3-asr-realtime:
    image: rookiezoe/qwen3-asr-realtime:latest
    container_name: qwen3-asr-server
    ipc: host
    ports:
      - '8080:8080'
    environment:
      # Model configuration
      # Supports: HF model ID (Qwen/Qwen3-ASR-1.7B), absolute path (/models/xxx), or relative path (./models/xxx)
      - QWEN3_ASR_MODEL_PATH=Qwen/Qwen3-ASR-1.7B

      # Server settings
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8080

      # vLLM settings
      - GPU_MEMORY_UTILIZATION=0.8
      - MAX_NEW_TOKENS=64
      # Model dtype: auto, half, float16, bfloat16, float, float32
      - MODEL_DTYPE=auto

      # VAD settings
      - VAD_ENABLED=true
      - VAD_THRESHOLD=0.5
      - VAD_SILENCE_DURATION_MS=400

      # Streaming settings
      - STREAMING_CHUNK_SIZE_SEC=2.0
      - AUTO_COMMIT_INTERVAL_SEC=60.0

      # Memory optimization
      - PYTORCH_ALLOC_CONF=expandable_segments:True

      # Logging
      - LOG_LEVEL=info

      # HuggingFace settings (optional)
      # - HF_TOKEN=your_token_here
      # - HF_ENDPOINT=https://hf-mirror.com
    volumes:
      # Mount HuggingFace cache to persist downloaded models
      - ~/.cache/huggingface:/root/.cache/huggingface

      # Optional: Mount local models directory
      # - ./models:/app/models

      # Optional: Mount custom initialization scripts
      # - ./entrypoint.d:/docker-entrypoint.d:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8080/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
